[{"content":"Comming Soon\n","date":"2023-08-23T19:44:57+09:00","image":"https://kimsehyoung.github.io/post/grpc/grpc_load_balancing/load-balancing_hu9853b85549f8f6a0aa4a260c374db0ce_55651_120x120_fill_box_smart1_3.png","permalink":"https://kimsehyoung.github.io/post/grpc/grpc_load_balancing/","title":"gRPC Load Balancing"},{"content":"RPC RPC(Remote Procedure Call)는 클라이언트가 서버의 procedure(함수)를 마치 로컬에 있는 것처럼 호출하는 것이다. 다음 동작 단계를 보면서, 어떤 건지 알아보자.\nRPC는 로컬 메서드를 호출하는 것처럼 보이지만, 클라이언트와 서버는 별도의 프로세스로 다른 주소 공간을 가지므로, 서로 통신을 위해서 JSON, Ptotobuf, Thrift 같은 IDL(Interface Definition Language)로 호출 규약을 정의한다. rpcgen으로 IDL 파일을 컴파일하여 클라이언트와 서버의 Stub 코드를 생성한다. Stub은 Source code(C++, Java, Python, Go\u0026hellip;)의 형태로 서버에서는 Stub을 사용하여 프로시저에 대한 기능 구현이 필요하다. 각 클라이언트, 서버에서는 Stub 코드를 같이 빌드한다. 클라이언트는 전달할 매개변수를 Mashalling하고, 로컬 Stub 프로시저를 호출하여 서버에 메시지를 전송한다. 서버는 Stub을 통해 해당 프로시저가 호출되고, 매개변수를 Unmarshalling하여 요청을 수행한 결과를 Mashalling하여 클라이언트에게 전송한다. 클라이언트는 해당 서버 프로시저에 대한 결과를 받으며, 마치 로컬 메서드를 호출하는 것처럼 사용을 할 수 있게 된다. (https://learn.microsoft.com/en-us/windows/win32/rpc/how-rpc-works)\ngRPC Google 내부에서 마이크로 서비스를 연결하는데 사용한 Stubby라는 RPC 인프라를 표준화한 오픈소스 프레임워크\n가장 큰 특징은 Probocol Buffers, HTTP/2를 사용\nProtobuf는 google에서 만든 구조화된 데이터를 직렬화하는 방식으로 JSON 형식보다 작은 크기로 효율적 HTTP/2는 헤더 압축, 이진 형식, 서버 푸시, 멀티플렉싱\u0026hellip; 으로 성능 향상을 가져옴 // Protobuf로 서비스 API를 정의 message HelloRequest { string msg = 1; } message HelloResponse { string msg = 1; } service HelloService { rpc SayHello (HelloRequest) returns (HelloResponse); } gRPC-Gateway gRPC는 좋은 장점들이 있지만, 몇 가지 고려할 점이 있다.\n개발자들이 gRPC에 익숙지 않거나, 기존 서비스들이 REST 기반이라면 한 번에 서비스 전체에 gRPC를 적용하기 어려움 브라우저에서 gRPC가 지원이 안 되기에, 추가적으로 gRPC-Web 또는 gRPC-Gateway 필요 이러한 이유들로 gRPC-Gateway를 사용할 수 있다.\ngRPC Gateway는 REST를 gRPC로 변환하는 리버스 프록시 서버를 생성하는 방식으로 gRPC, REST 모두 호출 가능하게 해준다.\n(https://github.com/grpc-ecosystem/grpc-gateway)\nPros and Cons Pros\nPolyglot 환경 (protobuf를 기반으로 gRPC가 지원하는 다양한 언어로 Stub코드 생성) 양방향 통신 (Unary, Client streaming, server streaming, Bidirectional Streaming) 네트워크 성능 (Protobuf, HTTP/2) API 문서 없이 Protobuf만으로 인터페이스 명세 (필요 시, gRPC-Gateway plugin으로 OpenAPI 문서 생성 가능) Interceptor, Load balancing 같은 유용한 내장 기능 제공 Cons\nJSON/REST를 주로 사용했다면, 러닝 커브로 인한 도입 어려움 gRPC는 브라우저 직접적인 지원이 안 되기에, 추가적인 방법이 필요 TCP 연결을 유지하는 HTTP/2의 특성으로 인해, 로드 밸런싱의 어려움 ","date":"2023-08-23T19:11:30+09:00","image":"https://kimsehyoung.github.io/post/grpc/grpc/grpc_hu6f115954a23a43b81942d129ea8277b1_80687_120x120_fill_box_smart1_3.png","permalink":"https://kimsehyoung.github.io/post/grpc/grpc/","title":"gRPC에 대해 알아보자"},{"content":" prerequisite container runtime Use containerd (containerd, CRI-O, docker) sudo apt-get update sudo apt-get install -y \\\\ ca-certificates \\\\ curl \\\\ gnupg \\\\ lsb-release sudo mkdir -p /etc/apt/keyrings curl -fsSL \u0026lt;https://download.docker.com/linux/ubuntu/gpg\u0026gt; | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg echo \\\\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \u0026lt;https://download.docker.com/linux/ubuntu\u0026gt; \\\\ $(lsb_release -cs) stable\u0026#34; | sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update sudo apt-get install containerd.io=1.6.14-1 sudo apt-mark hold containerd.io # Disabled cri plugin such as below line in config.toml after installing containerd package # disabled_plugins = [\u0026#34;cri\u0026#34;] # So, set the config to default # Use SystemdCgroup and restart daemon containerd config default | sudo tee /etc/containerd/config.toml sudo sed -i \u0026#39;s/SystemdCgroup = false/SystemdCgroup = true/\u0026#39; /etc/containerd/config.toml sudo systemctl restart containerd network overlay enables networking between nods br_netfilter enables networking between pods cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF sudo modprobe overlay sudo modprobe br_netfilter # sysctl params required by setup, params persist across reboots cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-ip6tables = 1 net.ipv4.ip_forward = 1 EOF # Apply sysctl params without reboot sudo sysctl --system swap off swap memory support from v 1.22 # Check swap memory \u0026#34;swapon -s\u0026#34; or \u0026#34;free -h\u0026#34; # Disable swap sudo swapoff -a # Disable swap on startup sudo sed -i \u0026#39;/ swap / s/^\\\\(.*\\\\)$/#\\\\1/g\u0026#39; /etc/fstab # Implementation after reboot (crontab -l 2\u0026gt;/dev/null; echo \u0026#34;@reboot /sbin/swapoff -a\u0026#34;) | crontab - || true setup cluster caution pod\u0026rsquo;s CIDR block overlap control-plane node TBD: use public/private IP for api server address\npod-cidr: set according to your environment\ne.g. Use 10.244.0.0/16 host: 192\u0026hellip;, docker: 172\u0026hellip;\n# Install packages needed to use the Kubernetes apt repository sudo apt-get update sudo apt-get install -y apt-transport-https ca-certificates curl # Download the Google Cloud public signing key: sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg \u0026lt;https://packages.cloud.google.com/apt/doc/apt-key.gpg\u0026gt; # Add the Kubernetes apt repository echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] \u0026lt;https://apt.kubernetes.io/\u0026gt; kubernetes-xenial main\u0026#34; | sudo tee /etc/apt/sources.list.d/kubernetes.list # Install sudo apt-get update apt-cache madison kubeadm | head -20 sudo apt-get install -y kubelet=1.26.0-00 kubeadm=1.26.0-00 kubectl=1.26.0-00 sudo apt-mark hold kubelet kubeadm kubectl # Check packages kubelet --version kubeadm version kubectl version --client # Pre-pull the required control-plane images kubeadm config images list --kubernetes-version=v1.26.0 sudo kubeadm config images pull --kubernetes-version=v1.26.0 # Set up the Kubernetes control plane sudo kubeadm init --apiserver-advertise-address=\u0026lt;private-ip\u0026gt; --apiserver-cert-extra-sans=\u0026lt;private-ip\u0026gt; --pod-network-cidr=\u0026lt;pod-cidr\u0026gt; --node-name $(hostname -s) mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config kubectl get nodes kubectl get namespaces kubectl get pods -n kube-system network plugins Use calico cni flannel: \u0026lsquo;10.244.0.0/16\u0026rsquo;, calico: \u0026lsquo;192.168.0.0/16\u0026rsquo; … To avoid overlapping, modify cidr to \u0026lsquo;10.244.0.0/16\u0026rsquo; curl \u0026lt;https://raw.githubusercontent.com/projectcalico/calico/v3.24.5/manifests/calico.yaml\u0026gt; -O # Edit \u0026#39;CALICO_IPV4POOL_CIDR\u0026#39; in calico.yml, if CIDR block is changed from default for avoiding overlap. kubectl apply -f calico.yaml kubectl describe node | egrep \u0026#39;^Name|PodCIDR\u0026#39; helm install curl -fsSL -o get_helm.sh \u0026lt;https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\u0026gt; chmod 700 get_helm.sh ./get_helm.sh helm version reference Read references while following below guide step by step\nset-up https://kubernetes.io/docs/setup/production-environment/container-runtimes/ https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/ runtime https://kubernetes.io/ko/docs/setup/production-environment/container-runtimes/https://github.com/containerd/containerd/blob/main/docs/getting-started.md network https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-networkhttps://projectcalico.docs.tigera.io/getting-started/kubernetes/self-managed-onprem/onpremises#install-calico-with-kubernetes-api-datastore-more-than-50-nodes swap memory https://kubernetes.io/ko/docs/concepts/architecture/nodes/#swap-memory port https://kubernetes.io/docs/reference/networking/ports-and-protocols/ helm https://helm.sh/docs/intro/install/ ","date":"2023-08-13T16:30:14+09:00","image":"https://kimsehyoung.github.io/post/kubernetes/kubeadm/kubeadm_hu52b047000e5acb39470b30f94d1ddcf0_25140_120x120_fill_box_smart1_3.png","permalink":"https://kimsehyoung.github.io/post/kubernetes/kubeadm/","title":"Kubernetes 설치"},{"content":"Trunk based 브랜치 관리가 간단하고, CI/CD 와 함께 신속, 지속적인 개발과 배포에 용이 코드베이스가 항상 배포 가능한 상태를 유지하므로, 긴급 수정이나 기능 추가가 빠르게 이루어짐. 모든 개발자가 단일 브랜치에서 작업하기 때문에, 코드 품질과 안정성 관리에 주의가 필요함. Branch\nmain short-term Git flow 2010 프로젝트의 안전성과 관리를 높이는데 초점을 맞춤. 브랜치 관리가 복잡하고, 신속한 배포가 어려움. Branch\nmain 항상 production에 배포 가능한 안정적인 코드를 유지하며, 모든 작업의 기준 브랜치 (permanent) develop 개발자가 feature 브랜치를 merge (permanent) feature 기능 개발을 위한 브랜치로, 개발이 완료되면 develop 브랜치로 merge release 배포 준비를 위해 QA(Intergration Test) 및 bug fix 후 main, develop로 merge hotfix 긴급한 버그 수정을 위한 브랜치로, main에서 분기하여 수정 후 main, develop으로 merge GitHub flow 2011 git flow 의 복잡성을 줄이기 위해 고안됨. 빠른 개발 및 배포와 피드백 Branch\nmain production에 배포되는 안정적인 버전의 브랜치이며, 좀 더 엄격한 규칙이 필요(permanent) feature 기능 개발을 위한 브랜치로, 개발이 완료되면 main 브랜치로 merge 브랜치명은 작업 내용을 표현할 수 있도록 명명 GitLab flow 2014 Git flow와 GitHub flow의 중간 정도의 혼합 방식 환경 별 브랜치 사용 Branch\nmain 항상 production에 배포 가능한 안정적인 코드를 유지하며, 모든 작업의 기준 브랜치 (permanent) feature 기능 개발이 완료되면 main 브랜치로 merge staging(optional) staging환경에서 변경 사항을 테스트 및 검증하여 문제가 없으면 production으로 병함 (permanent) production 실제 서비스에 배포되는 브랜치 (permanent) 어떻게 적용하면 좋을까? 복잡하고 큰 규모의 프로젝트, 정기 릴리스가 필요한 때 Git Flow를 적용하면 좋을 것 같다. 차량, IOT 기기와 같은 분야에서 많이 이용될 것이고, 참여했던 차량 SW 프로젝트에서 기반으로 한 것이 Git Flow이다.\n빠른 변화와 피드백, 하루에도 여러 번의 배포가 이루어진다면 Trunk Based, GitHub Flow 기반의 Workflow를 사용할 수 있다. SaaS, Agile 방식에 적합하고, 단순하지만 그만큼 자동화 테스트, 롤백, 코드 리뷰와 같은 개발 문화 등이 이루어져야 할 것이다.\nWorkflow는 딱 정하는 것이 아닌 조직, 프로젝트, 여러 가지 현재 상황에 맞추어 가는 것이 필요하다. 실제로 안정성을 위해 \u0026lsquo;feature-develop-main\u0026rsquo;, \u0026lsquo;feature-main-production\u0026rsquo;로 구성을 했다가, CI/CD에 unit test, e2e를 적용 후에 \u0026lsquo;feature-main\u0026rsquo;으로 변경을 했었다.\n","date":"2023-08-13T10:15:29+09:00","image":"https://kimsehyoung.github.io/post/git/workflow/git_workflow_hu3d03a01dcc18bc5be0e67db3d8d209a6_2538919_120x120_fill_q75_box_smart1.jpg","permalink":"https://kimsehyoung.github.io/post/git/workflow/","title":"Git Workflow"},{"content":"Network tcpdump tcpdump prints out a description of the contents of packets on a network interface. https://www.tcpdump.org/manpages/tcpdump.1.html\ntcpdump dst 192.168.11.11 and port 22 tcpdump -i eno1 host 192.168.11.11 tcpdump host 192.168.11.11 and tcp port 443 -w tcpdump.log tcpdump -r tcpdump.log nc nc scans TCP and UDP connections\nhttps://linux.die.net/man/1/nc\nnc -zv 192.168.123.123 443 =\u0026gt; Connection to 192.168.123.123 443 port [tcp/*] succeeded! arping arping sends ARP request to a neighbor host.\nhttps://man7.org/linux/man-pages/man8/arping.8.html\nsudo arping 192.168.123.123 =\u0026gt; 60 bytes from a1:b2:c3:d4:e5:f6 (192.168.123.123) ... ETC top top displays system info as well as a list of processes or threads currently managed by the Linux Kernel.\nhttps://man7.org/linux/man-pages/man1/top.1.html\ntop -p \u0026lt;pid\u0026gt; -H tee tee reads from standard input and writes to standard output and files.\nhttps://man7.org/linux/man-pages/man1/tee.1.html\necho \u0026#34;hello\u0026#34; | tee OUTFILE cat OUTFILE | tee NEWFILE echo \u0026#34;hello\u0026#34; | tee -a OUTFILE echo \u0026#34;hello\u0026#34; | tee -a OUTFILE /dev/null Why use tee?\n-\u0026gt; It might be thought that echo, cat is sufficient. But, They can’t write into root files.\n# \u0026#34;permission denied\u0026#34; occured. sudo echo \u0026#34;Hello\u0026#34; \u0026gt;\u0026gt; /root/test.txt # It works successfully. echo \u0026#34;Hello\u0026#34; | sudo tee -a /root/test.txt lsof lsof lists file information about files opened by processes.\nhttps://man7.org/linux/man-pages/man8/lsof.8.html\nsudo lsof -a -p 1234567 -d cwd COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME python3 1234567 test cwd DIR 8,2 4096 5656565 /home/test/test-server screen screen multiplexes a physical terminal to each virtual terminal.\nhttps://linux.die.net/man/1/screen\nWhen a long-running task on a remote machine is performed, It helps that the SSH session is terminated and the work is corrupted or lost.\n# Create a new session screen -S test # Detach the session ctrl-a + d screen -ls # Resume a detached screen session. screen -r test # Exit with the session termination. exit pstree pstree displays a tree of process.\nhttps://man7.org/linux/man-pages/man1/pstree.1.html\nscreen -S test ./test-app \u0026amp; ctrl-a + d screen -ls pstree -p 1234567 lsblk lsblk lists information about all available or the specified block devices.\nhttps://man7.org/linux/man-pages/man8/lsblk.8.html\nlsblk -o name,rota,size,mountpoint mount mount serves to attach the file system on some device to the specific directory.\nhttps://linux.die.net/man/8/mount\nmount /dev/sda /backup unmount /dev/sda df -h ","date":"2023-08-12T23:43:26+09:00","image":"https://kimsehyoung.github.io/post/linux/commands/linux_commands_hu3d03a01dcc18bc5be0e67db3d8d209a6_1006554_120x120_fill_q75_box_smart1.jpg","permalink":"https://kimsehyoung.github.io/post/linux/commands/","title":"리눅스 명령어"}]